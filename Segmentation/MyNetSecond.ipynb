{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# массивы, рандом\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# файлы\n",
    "from os.path import join as pjoin\n",
    "import os\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# модельки\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# аугментация\n",
    "import albumentations as album\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# отображение\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchinfo\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from board import uniqufy_path, create_image_plot\n",
    "# writer = SummaryWriter()\n",
    "# writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "# метрики\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "# оптимизаторы, изменение lr\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "# лосы\n",
    "from segmentation_models_pytorch.losses import LovaszLoss, DiceLoss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/tiff/'\n",
    "DATA_CLASSES = \"data/label_class_dict.csv\"\n",
    "PRED_TEST = 'pred/test/'\n",
    "PRED_VALID = 'pred/valid/'\n",
    "\n",
    "MEAN_IMAGE_TRANSFORM = [0.4363, 0.4328, 0.3291]\n",
    "MEAN_IMAGE_STD = [0.2129, 0.2075, 0.2038]\n",
    "SIZE_IMAGE = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# BOARD = SummaryWriter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы:  ['background', 'road']\n",
      "Классы RGB значений:  [[0, 0, 0], [255, 255, 255]]\n"
     ]
    }
   ],
   "source": [
    "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'train_labels')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'val_labels')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test_labels')\n",
    "\n",
    "class_dict = pd.read_csv(\"data/label_class_dict.csv\")\n",
    "CLASSES = class_dict['name'].tolist()\n",
    "CLASSES_RGB = class_dict[['r','g','b']].values.tolist()\n",
    "\n",
    "print('Классы: ', CLASSES)\n",
    "print('Классы RGB значений: ', CLASSES_RGB)\n",
    "\n",
    "with open('data/parametrs.json', 'r', encoding='utf-8') as f:\n",
    "    PARAMETERS = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОТОБРАЖЕНИЕ\n",
    "def print_image(**images):\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n_images, idx + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(name.replace('_', ' ').title(), fontsize=20)\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# ПРЕОБРАЗОВАНИЯ\n",
    "\n",
    "\n",
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis=-1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "    return semantic_map\n",
    "\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis=-1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "    return x\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def prepare_to_network():\n",
    "    return album.Lambda(image=to_tensor, mask=to_tensor)\n",
    "\n",
    "\n",
    "def transform_train():\n",
    "    train_transform = album.Compose(\n",
    "        [\n",
    "            album.RandomCrop(height=SIZE_IMAGE, width=SIZE_IMAGE,\n",
    "                             always_apply=True),\n",
    "            album.OneOf(\n",
    "                [\n",
    "                    album.HorizontalFlip(p=1),\n",
    "                    album.VerticalFlip(p=1),\n",
    "                    album.RandomRotate90(p=1),\n",
    "                ],\n",
    "                p=0.75,\n",
    "            ),\n",
    "            album.Normalize(mean=MEAN_IMAGE_TRANSFORM,\n",
    "                            std=MEAN_IMAGE_STD, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "def transform_test():\n",
    "    test_transform = album.Compose([\n",
    "        album.PadIfNeeded(min_height=1536, min_width=1536,\n",
    "                          always_apply=True, border_mode=0),\n",
    "    ])\n",
    "    return test_transform\n",
    "\n",
    "# ПОЛУЧЕНИЕ ПАРАМЕТРОВ ДЛЯ ОБУЧЕНИЯ\n",
    "\n",
    "\n",
    "def get_model(param, encoder, encoder_weights, classes, activation):\n",
    "    if (param == 'unet'):\n",
    "        return smp.Unet(\n",
    "            encoder_name=encoder,\n",
    "            encoder_weights=encoder_weights,\n",
    "            classes=len(classes),\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "    return smp.Unet(\n",
    "        encoder_name=encoder,\n",
    "        encoder_weights=encoder_weights,\n",
    "        classes=len(classes),\n",
    "        activation=activation,)\n",
    "\n",
    "\n",
    "def get_function_loss(param):\n",
    "    if (param == 'DiceLoss'):\n",
    "        return DiceLoss(mode='binary')\n",
    "\n",
    "    return LovaszLoss(mode='binary')\n",
    "\n",
    "\n",
    "def get_optimizer(param, model, lr, weight_decay: float = 0.1, momentum: float = 0.9):\n",
    "    if param == 'Adam':\n",
    "        return torch.optim.Adam(\n",
    "            params=model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "\n",
    "def get_scheduler(param, optimizer):\n",
    "    if param['name'] == 'ReduceLROnPlateau':\n",
    "        return ReduceLROnPlateau(optimizer, 'min',\n",
    "                                 patience=param['patience'], threshold=param['threshold'],\n",
    "                                 cooldown=param['cooldown'], factor=param['factor'])\n",
    "        # return ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    return CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_metric(param, iou, acc, dice):\n",
    "    if param == 'iou':\n",
    "        return iou\n",
    "    if param == 'acc':\n",
    "        return acc\n",
    "    if param == 'dice':\n",
    "        return dice\n",
    "    return 0\n",
    "\n",
    "def dice_score(pred: torch.Tensor, mask: torch.Tensor):\n",
    "    intersection = torch.sum(pred * mask)\n",
    "    dice = (2. * intersection) / (torch.sum(pred) + torch.sum(mask))\n",
    "    return dice.item()\n",
    "\n",
    "def pixel_accuracy(pred: torch.Tensor, mask: torch.Tensor):\n",
    "    correct = torch.eq(pred, mask).int()\n",
    "    return float(correct.sum()) / float(correct.numel())\n",
    "\n",
    "# САМО ОБУЧЕНИЕ\n",
    "\n",
    "def train_step(model, criterion, optimizer, dataloader, epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "    return train_loss.item()\n",
    "\n",
    "\n",
    "def valid_step(model, criterion, dataloader, epoch, BOARD):\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "\n",
    "    iou = BinaryJaccardIndex(num_classes=2)\n",
    "    iou.to(DEVICE)\n",
    "\n",
    "    dice = acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "\n",
    "            iou(output, labels)\n",
    "            dice += dice_score(output, labels)\n",
    "            acc += pixel_accuracy(output, labels)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss\n",
    "\n",
    "            BOARD.add_figure('valid_sample_' + str(i), create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASSES_RGB),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASSES_RGB)),\n",
    "                epoch)\n",
    "\n",
    "        dice_value = dice / len(dataloader)\n",
    "        acc_value = acc / len(dataloader)\n",
    "\n",
    "        valid_loss = running_loss / len(dataloader)\n",
    "        return valid_loss.item(), iou.compute().item(), dice_value, acc_value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadsDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            class_rgb_values=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.image_paths = [os.path.join(images_dir, image_id) for image_id in sorted(os.listdir(images_dir))]\n",
    "        self.mask_paths = [os.path.join(masks_dir, image_id) for image_id in sorted(os.listdir(masks_dir))]\n",
    "\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка валидации и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = RoadsDataset(x_valid_dir, y_valid_dir,\n",
    "                             class_rgb_values=CLASSES_RGB, augmentation=transform_test(), preprocessing=prepare_to_network())\n",
    "test_dataset = RoadsDataset(x_test_dir, y_test_dir,\n",
    "                            class_rgb_values=CLASSES_RGB, augmentation=transform_test(), preprocessing=prepare_to_network())\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБУЧЕНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "NUM_WORKERS = 0\n",
    "# mobilenet_v2\n",
    "\n",
    "# http://84.237.51.132:9032/\n",
    "# aboba21932aboba пажилой пароль от второго контейнера\n",
    "\n",
    "# пока по токену логинься t05042023-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec(PARAMETERS[\"paramerts\"][0]['func'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2ebe8234a4f93931a91351d1792f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f100f9f0864b1f94813bdd2af88c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "for (index_param, param) in tqdm(enumerate(PARAMETERS[\"paramerts\"])):\n",
    "    id = f\"{param['model']}_1_{param['encoder']}_{param['learning_rate']}_{param['metric']}_{param['optimizer']}_{param['scheduler']['name']}_{param['loss']}\"\n",
    "    TBpath = uniqufy_path('res/' + id)\n",
    "    BOARD = SummaryWriter(TBpath)\n",
    "\n",
    "    LEARNING_RATE = param['learning_rate']\n",
    "\n",
    "    ACTIVATION = nn.ReLU\n",
    "\n",
    "    # МОДЕЛЬ\n",
    "    model = get_model(param['model'], param['encoder'],\n",
    "                      'imagenet', CLASSES, ACTIVATION)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # ЗАГРУЗКА\n",
    "    train_dataset = RoadsDataset(x_train_dir, y_train_dir,\n",
    "                                 class_rgb_values=CLASSES_RGB, augmentation=transform_train(), preprocessing=prepare_to_network())\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    # ПАРАМЕТРЫ ДЛЯ ОБУЧЕНИЯ\n",
    "    criterion = get_function_loss(param['loss'])\n",
    "    optimizer = get_optimizer(\n",
    "        param['optimizer'], model, LEARNING_RATE, weight_decay=param['weight_decay'])\n",
    "    scheduler = get_scheduler(param['scheduler'], optimizer)\n",
    "\n",
    "    # ПЕРЕМЕННЫЕ ДЛЯ ГРАФИКОВ\n",
    "    len_steps = len(train_dataloader)\n",
    "\n",
    "    # ОБУЧЕНИЕ\n",
    "    pbar = tqdm(range(EPOCHS))\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            BOARD.add_scalar('learning rate', float(param_group['lr']), epoch)\n",
    "\n",
    "        train_loss = train_step(\n",
    "            model, criterion, optimizer, train_dataloader, epoch, EPOCHS)\n",
    "        valid_loss, metric_iou, metric_dice, metric_acc = valid_step(\n",
    "            model, criterion, valid_dataloader, epoch, BOARD)\n",
    "\n",
    "        scheduler.step(get_metric(\n",
    "            param[\"metric\"], metric_iou, metric_acc, metric_dice))\n",
    "\n",
    "        BOARD.add_scalar('loss_valid', valid_loss, epoch)\n",
    "        BOARD.add_scalar('loss_train', train_loss, epoch)\n",
    "\n",
    "        BOARD.add_scalar('metric_iou', metric_iou, epoch)\n",
    "        BOARD.add_scalar('metric_dice', metric_dice, epoch)\n",
    "        BOARD.add_scalar('metric_acc', metric_acc, epoch)\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_description(\n",
    "            f'{param[\"metric\"]}: {get_metric(param[\"metric\"], metric_iou, metric_acc, metric_dice):.2f}  | train/valid loss: {train_loss:.4f}/{valid_loss:.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "            # METRICS(output, labels)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            BOARD.add_figure('test_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASSES_RGB),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASSES_RGB)),\n",
    "                i)\n",
    "\n",
    "            # BOARD.add_scalar('metric_loss', METRICS.compute().item(), i)\n",
    "\n",
    "    BOARD.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
