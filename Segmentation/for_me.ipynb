{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# МЕТРИКИ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BinaryJaccardIndex\n",
    "\n",
    "Метрика Binary Jaccard Index (индекс Жаккара) используется для оценки качества бинарной сегментации изображений. Она измеряет сходство между двумя множествами (например, множеством пикселей в сегментированном изображении и множеством пикселей в эталонном изображении) путем измерения пересечения их элементов относительно их объединения.\n",
    "\n",
    "Индекс Жаккара определяется следующим образом:\n",
    "J(A,B) = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "где A и B - два множества, |A ∩ B| - количество элементов, которые присутствуют в обоих множествах, а |A ∪ B| - количество элементов, присутствующих в любом из двух множеств.\n",
    "\n",
    "В контексте бинарной сегментации, множество A представляет сегментированное изображение, а множество B - эталонное изображение. Индекс Жаккара равен 1, если сегментированное изображение и эталонное изображение совпадают, и меньше 1 в противном случае.\n",
    "\n",
    "Binary Jaccard Index - это метрика, которая может быть использована для оптимизации моделей, которые занимаются бинарной сегментацией изображений, например, с использованием глубокого обучения. Чем ближе значение индекса Жаккара к 1, тем более точно сегментированное изображение соответствует эталонному изображению."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОПТИМИЗАТОРЫ\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    "\n",
    "Adam (Adaptive Moment Estimation) - это оптимизатор для градиентного спуска, который был предложен Diederik P. Kingma и Jimmy Ba в 2014 году. Он используется для обучения нейронных сетей и считается одним из наиболее эффективных методов оптимизации.\n",
    "\n",
    "Adam является комбинацией двух других методов оптимизации - Adaptive Gradient Algorithm (AdaGrad) и Root Mean Square Propagation (RMSProp). Он использует адаптивные скорости обучения для каждого параметра на основе первого и второго моментов градиента.\n",
    "\n",
    "Вот формулы, используемые Adam:\n",
    "\n",
    "Вычисление первого момента градиента (mean):\n",
    "m_t = β1 * m_{t-1} + (1 - β1) * g_t\n",
    "где m_t - первый момент градиента на шаге t, g_t - градиент на шаге t, и β1 - коэффициент затухания для первого момента.\n",
    "\n",
    "Вычисление второго момента градиента (variance):\n",
    "v_t = β2 * v_{t-1} + (1 - β2) * g_t^2\n",
    "где v_t - второй момент градиента на шаге t, и β2 - коэффициент затухания для второго момента.\n",
    "\n",
    "Корректировка смещения первого и второго моментов градиента:\n",
    "m_t_hat = m_t / (1 - β1^t)\n",
    "v_t_hat = v_t / (1 - β2^t)\n",
    "\n",
    "Обновление весов с помощью скорости обучения (learning rate):\n",
    "w_t = w_{t-1} - α * m_t_hat / (sqrt(v_t_hat) + ε)\n",
    "где w_t - веса на шаге t, α - скорость обучения, и ε - небольшое число для предотвращения деления на ноль.\n",
    "\n",
    "Adam преимущественно используется для решения задач машинного обучения, таких как классификация, детектирование объектов и сегментация. Он демонстрирует высокую скорость сходимости и эффективно справляется с проблемами разреженности градиента и неоднородности признаков.\n",
    "\n",
    "- params (обязательный): итерируемый объект, содержащий параметры модели, которые нужно оптимизировать.\n",
    "- lr (необязательный, по умолчанию 1e-3): скорость обучения (learning rate), определяющая шаг оптимизации.\n",
    "- betas (необязательный, по умолчанию (0.9, 0.999)): кортеж из двух коэффициентов, определяющих экспоненциальный затухание для двух моментов первого и второго порядка в методе Adam.\n",
    "- eps (необязательный, по умолчанию 1e-8): параметр-эпсилон, который используется для стабилизации вычислений.\n",
    "- weight_decay (необязательный, по умолчанию 0): коэффициент, определяющий степень регуляризации весов.\n",
    "- amsgrad (необязательный, по умолчанию False): флаг, определяющий, будет ли использоваться адаптивный метод скользящего среднего (AMSGrad) для оптимизации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**weight_decay** - это параметр регуляризации, который помогает снизить переобучение модели. Он добавляет штраф к функции потерь, зависящий от величины весов модели.\n",
    "\n",
    "Параметр weight_decay в оптимизаторе определяет коэффициент регуляризации L2 (также известной как Ridge регрессия). Коэффициент weight_decay умножает веса на каждом шаге обновления на значение, близкое к единице, чтобы сделать веса более \"легкими\" и уменьшить их значения.\n",
    "\n",
    "Фактически, при использовании weight_decay, при обновлении весов модели учитываются две составляющие: первая - это градиент функции потерь, а вторая - это L2-регуляризация, которая приводит к уменьшению весов на каждом шаге обновления.\n",
    "\n",
    "Значение weight_decay выбирается эмпирически и зависит от данных и конкретной модели, которую нужно обучить. Большие значения weight_decay соответствуют более сильной регуляризации, но могут снизить точность модели. Малые значения weight_decay могут привести к переобучению, если модель слишком сложна или данных слишком мало.\n",
    "\n",
    "В целом, weight_decay - это один из методов борьбы с переобучением в моделях машинного обучения, позволяющий балансировать между смещением и разбросом.\n",
    "\n",
    "**L2-регуляризация** (также известная как Ridge регрессия) - это метод регуляризации, который добавляет к функции потерь штраф за большие значения весов модели. Формула L2-регуляризации выглядит следующим образом:\n",
    "\n",
    "L2-регуляризация = λ * ||w||^2\n",
    "\n",
    "где λ - это коэффициент регуляризации, а ||w||^2 - это квадрат нормы вектора весов модели.\n",
    "\n",
    "Для применения L2-регуляризации в градиентном спуске мы добавляем штраф к функции потерь, который вычисляется как произведение λ на квадрат нормы вектора весов:\n",
    "\n",
    "L = L0 + λ * ||w||^2\n",
    "\n",
    "где L0 - исходная функция потерь.\n",
    "\n",
    "При градиентном спуске мы минимизируем эту новую функцию потерь, чтобы получить веса модели, которые не только хорошо соответствуют тренировочным данным, но и не слишком большие. Это помогает избежать переобучения и улучшить обобщающую способность модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "\n",
    "**L1-регуляризация** (также известная как Lasso регрессия) - это метод регуляризации, который добавляет к функции потерь штраф за большие значения весов модели, пропорциональный модулю весов.\n",
    "\n",
    "Формально, L1-регуляризация выглядит следующим образом:\n",
    "\n",
    "L1-регуляризация = λ * ||w||1\n",
    "\n",
    "где λ - это коэффициент регуляризации, а ||w||1 - это L1-норма вектора весов модели.\n",
    "\n",
    "L1-норма вектора весов - это сумма модулей всех элементов вектора весов. Таким образом, L1-регуляризация штрафует большие значения весов модели, превращая некоторые из них в ноль и приводя к созданию разреженной модели, где только некоторые признаки являются значимыми для предсказания.\n",
    "\n",
    "L1-регуляризация может быть полезна в задачах машинного обучения, где необходимо выделить наиболее важные признаки из большого числа доступных. Также она может быть эффективной в задачах с высокой размерностью данных, где многие признаки не имеют большого влияния на результаты моделирования.\n",
    "\n",
    "Недостатком L1-регуляризации является то, что она может создавать модели с границами решений, что может быть нежелательным в некоторых случаях. Также, по сравнению с L2-регуляризацией, вычисление градиента функции потерь с использованием L1-регуляризации более сложно, так как она не дифференцируема в точке 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# УЛУЧШЕНИЕ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReduceLROnPlateau\n",
    "\n",
    "ReduceLROnPlateau - это колбэк (callback) в библиотеке Keras, который позволяет автоматически уменьшать скорость обучения (learning rate) модели, если происходит стагнация в процессе обучения.\n",
    "\n",
    "Когда ReduceLROnPlateau применяется, он мониторит заданную метрику (например, потери на проверочном наборе данных) на протяжении заданного числа эпох. Если в течение определенного числа эпох метрика не улучшается, ReduceLROnPlateau уменьшает скорость обучения на заданный коэффициент (обычно вдвое или втрое). Это позволяет улучшить качество модели и избежать проблемы, когда скорость обучения слишком высока и приводит к расхождению в процессе обучения.\n",
    "\n",
    "ReduceLROnPlateau может использоваться с различными типами моделей, например, с нейронными сетями для классификации, сегментации и обнаружения объектов, а также с моделями глубокого обучения для обработки изображений и текстов.\n",
    "\n",
    "ReduceLROnPlateau является мощным инструментом для улучшения процесса обучения модели и помогает снизить уровень сложности обучения за счет динамической регулировки скорости обучения.\n",
    "\n",
    "- optimizer (обязательный): оптимизатор, для которого будет производиться регулирование скорости обучения.\n",
    "- mode (необязательный, по умолчанию 'min'): определяет, какая метрика модели будет отслеживаться ('min' для минимизации метрики, 'max' для максимизации метрики).\n",
    "- factor (необязательный, по умолчанию 0.1): коэффициент, на который будет уменьшаться скорость обучения.\n",
    "- patience (необязательный, по умолчанию 10): количество эпох, в течение которых метрика не должна улучшаться, чтобы уменьшить скорость обучения.\n",
    "- threshold (необязательный, по умолчанию 1e-4): пороговое значение, ниже которого считается, что метрика не улучшилась.\n",
    "- threshold_mode (необязательный, по умолчанию 'rel'): определяет, какой пороговый режим используется ('rel' для относительного значения, 'abs' для абсолютного значения).\n",
    "- cooldown (необязательный, по умолчанию 0): количество эпох, на которое обучение будет остановлено после уменьшения скорости обучения.\n",
    "- min_lr (необязательный, по умолчанию 0): минимальное значение скорости обучения.\n",
    "- verbose (необязательный, по умолчанию False): если True, будет выведено сообщение о каждом событии, связанном с уменьшением скорости обучения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosineAnnealingWarmRestarts\n",
    "\n",
    "CosineAnnealingWarmRestarts - это метод изменения learning rate в процессе обучения нейронной сети. Он используется для улучшения сходимости оптимизации, сокращения времени обучения и увеличения точности модели.\n",
    "\n",
    "Метод CosineAnnealingWarmRestarts представляет собой комбинацию двух методов изменения learning rate: CosineAnnealingLR и WarmRestartLR. Первый метод изменяет learning rate по косинусоидальной кривой, а второй метод устанавливает learning rate в начале каждой эпохи обучения в некоторое начальное значение.\n",
    "\n",
    "Алгоритм CosineAnnealingWarmRestarts заключается в следующем:\n",
    "\n",
    "- Устанавливается начальное значение learning rate.\n",
    "- Обучение проходит в течение нескольких эпох с постоянным learning rate.\n",
    "- После окончания каждой эпохи learning rate сбрасывается до начального значения.\n",
    "- Затем learning rate изменяется по косинусоидальной кривой до нуля.\n",
    "- Процесс повторяется с начальным значением learning rate.\n",
    "- Таким образом, алгоритм обеспечивает сначала быстрое уменьшение learning rate, а затем медленное уменьшение до нуля. При этом происходит сброс learning rate в начальное значение, что позволяет избежать застревания в локальных минимумах.\n",
    "\n",
    "Параметры CosineAnnealingWarmRestarts включают начальное значение learning rate, периоды обучения (в эпохах), множитель для снижения learning rate, фактор снижения learning rate при сбросе и т.д."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ФУНКЦМЯ ПОТЕРЬ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Loss \n",
    "Dice Loss - это метрика и функция потерь, используемые для задач сегментации изображений, которые позволяют оценить сходство между сегментированным изображением и маской-эталоном.\n",
    "\n",
    "Формально, Dice Loss определяется следующим образом:\n",
    "\n",
    "Dice Loss = 1 - 2 * (|X ∩ Y|) / (|X| + |Y|)\n",
    "\n",
    "где X и Y - это множества пикселей на сегментированном изображении и маске-эталоне соответственно, |X| и |Y| - это их размеры (количество пикселей), а |X ∩ Y| - это количество пикселей, которые содержатся в обоих множествах.\n",
    "\n",
    "Интуитивно, Dice Loss показывает, насколько хорошо сегментированное изображение совпадает с маской-эталоном. Если Dice Loss равен 0, это означает полное несоответствие между сегментированным изображением и маской-эталоном, а если он равен 1, это означает идеальное совпадение.\n",
    "\n",
    "Smp.utils.losses.DiceLoss - это реализация Dice Loss в библиотеке segmentation_models_pytorch (SMP) для задач сегментации изображений. Она принимает на вход сегментированное изображение и маску-эталон, вычисляет значение Dice Loss и возвращает его как значение функции потерь. Это позволяет использовать Dice Loss в качестве функции потерь при обучении моделей для задач сегментации в SMP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аналоги**\n",
    "\n",
    "Существует несколько аналогов Dice Loss, которые также используются в задачах сегментации изображений. Некоторые из них:\n",
    "\n",
    "**Jaccard Loss** - это метрика и функция потерь, которая определяется как 1 - Jaccard Index, где Jaccard Index вычисляется как |X ∩ Y| / |X ∪ Y|. Он оценивает сходство между сегментированным изображением и маской-эталоном и также может использоваться как функция потерь для обучения моделей.\n",
    "\n",
    "**Binary Cross-Entropy Loss** - это стандартная функция потерь для бинарной классификации, которая широко используется в задачах сегментации. Она определяется как -y * log(p) - (1-y) * log(1-p), где y - это метка класса (0 или 1), p - это вероятность принадлежности к классу 1, предсказанная моделью.\n",
    "\n",
    "**Focal Loss** - это функция потерь, которая была разработана для улучшения обучения моделей при наличии большого количества легко классифицируемых примеров. Она определяется как -α(1-p)^γ * log(p) - (1-α)p^γ * log(1-p), где α - это вес для уравновешивания классов, γ - это параметр для настройки уверенности модели в своих предсказаниях.\n",
    "\n",
    "**Lovász-Softmax Loss** - это функция потерь, которая определяется на основе монотонного свойства показателя Жаккара и позволяет обучать модели, которые лучше обрабатывают неоднородные сегменты и границы объектов.\n",
    "\n",
    "Каждая из этих функций потерь имеет свои преимущества и недостатки и может быть использована в зависимости от конкретной задачи и требований."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**примеры**\n",
    "\n",
    "Dice Loss - хорошо подходит для задач сегментации медицинских изображений, таких как определение опухолей или диагностика заболеваний глаза.\n",
    "\n",
    "Jaccard Loss - также хорошо подходит для сегментации медицинских изображений, особенно когда важно точно измерять перекрытие между объектами на изображении.\n",
    "\n",
    "Binary Cross-Entropy Loss - это стандартная функция потерь для бинарной классификации, и она может использоваться для задачи сегментации, когда объекты на изображении являются двоичными (например, наличие/отсутствие опухоли).\n",
    "\n",
    "Focal Loss - может быть полезна при работе с задачами, где дисбаланс классов является проблемой, например, в задачах обнаружения объектов на изображениях.\n",
    "\n",
    "Lovász-Softmax Loss - эта функция потерь подходит для задач сегментации, особенно когда объекты на изображении имеют неоднородные границы и формы, например, в задачах сегментации дорожных сетей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
